{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating one token at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the models\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pretrained model and tokenizer from HuggingFace\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sentence to tokenize it\n",
    "text = \"She only cooks eggs when I am not\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3347,   691, 38383,  9653,   618,   314,   716,   407]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show tokens as numbers \n",
    "inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(3347)</td>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(691)</td>\n",
       "      <td>only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(38383)</td>\n",
       "      <td>cooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(9653)</td>\n",
       "      <td>eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(618)</td>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(314)</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tensor(716)</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(407)</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id   token\n",
       "0   tensor(3347)     She\n",
       "1    tensor(691)    only\n",
       "2  tensor(38383)   cooks\n",
       "3   tensor(9653)    eggs\n",
       "4    tensor(618)    when\n",
       "5    tensor(314)       I\n",
       "6    tensor(716)      am\n",
       "7    tensor(407)     not"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing pandas to show tokenization\n",
    "import pandas as pd\n",
    "\n",
    "# function to show tokenization result\n",
    "def show_tokenization(inputs):\n",
    "    return pd.DataFrame(\n",
    "        [(id, tokenizer.decode(id)) for id in inputs[\"input_ids\"][0]],\n",
    "        columns=[\"id\", \"token\"],\n",
    "    )\n",
    "\n",
    "show_tokenization(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>10801</td>\n",
       "      <td>cooking</td>\n",
       "      <td>0.145505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>287</td>\n",
       "      <td>in</td>\n",
       "      <td>0.065937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>1363</td>\n",
       "      <td>home</td>\n",
       "      <td>0.064642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>1762</td>\n",
       "      <td>working</td>\n",
       "      <td>0.062760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>379</td>\n",
       "      <td>at</td>\n",
       "      <td>0.059329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     token  probability\n",
       "10801  10801   cooking     0.145505\n",
       "287      287        in     0.065937\n",
       "1363    1363      home     0.064642\n",
       "1762    1762   working     0.062760\n",
       "379      379        at     0.059329"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate probabilities for the next token\n",
    "\n",
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits[:, -1, :]\n",
    "    probabilities = torch.nn.functional.softmax(logits[0], dim=-1)\n",
    "\n",
    "def show_next(probabilities, top_n=5):\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            (id, tokenizer.decode(id), p.item())\n",
    "            for id, p in enumerate(probabilities)\n",
    "            if p.item()\n",
    "        ],\n",
    "        columns=[\"id\", \"token\", \"probability\"]\n",
    "    ).sort_values(\"probability\", ascending=False).head(top_n)\n",
    "\n",
    "show_next(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token id: 10801\n",
      "Next token:  cooking\n"
     ]
    }
   ],
   "source": [
    "# the token id for the most probable next token\n",
    "next_token_id = torch.argmax(probabilities).item()\n",
    "\n",
    "print(f\"Next token id: {next_token_id}\")\n",
    "print(f\"Next token: {tokenizer.decode(next_token_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She only cooks eggs when I am not cooking'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appending the text\n",
    "text = text + tokenizer.decode(next_token_id)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: She only cooks eggs when I am not cooking\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Next tokens probabilities:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>them</td>\n",
       "      <td>0.131220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>.</td>\n",
       "      <td>0.104529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>,</td>\n",
       "      <td>0.084879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>340</td>\n",
       "      <td>it</td>\n",
       "      <td>0.068265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>553</td>\n",
       "      <td>,\"</td>\n",
       "      <td>0.051667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  token  probability\n",
       "606  606   them     0.131220\n",
       "13    13      .     0.104529\n",
       "11    11      ,     0.084879\n",
       "340  340     it     0.068265\n",
       "553  553     ,\"     0.051667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generating more tokens\n",
    "# importing display\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# show text\n",
    "print(f\"Text: {text}\")\n",
    "\n",
    "#convert into tokens\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# calculate probabilities for the next token\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits[:, -1, :]\n",
    "    probabilities = torch.nn.functional.softmax(logits[0], dim=-1)\n",
    "\n",
    "# show the texts\n",
    "display(Markdown(\"**Next tokens probabilities:**\"))\n",
    "display (show_next(probabilities))\n",
    "\n",
    "# the token id for the most probable next token\n",
    "next_token_id = torch.argmax(probabilities).item()\n",
    "\n",
    "text = text + tokenizer.decode(next_token_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "She only cooks eggs when I am not cooking them. I don't cook eggs when I am not cooking them. I don't cook eggs when I am not cooking them. I don't cook eggs when I am not cooking them. I don't cook eggs when I am not cooking them. I don't cook eggs when I am not cooking them. I don't cook eggs when I am not cooking them. I don't cook eggs when I am not cooking them. I don't cook eggs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use generate method\n",
    "output = model.generate(**inputs, max_length=100, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# show generated text\n",
    "display(Markdown(tokenizer.decode(output[0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
